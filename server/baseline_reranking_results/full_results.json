{
  "bm25": [
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 2
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 1.0,
      "R@10": 1.0,
      "R@20": 1.0,
      "MRR": 0.5,
      "hits": 1,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 8
    }
  ],
  "bm25_reranked": [
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 2
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 1.0,
      "R@10": 1.0,
      "R@20": 1.0,
      "MRR": 0.5,
      "hits": 1,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 8
    }
  ],
  "e5": [
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.5,
      "R@20": 0.5,
      "MRR": 0.1,
      "hits": 1,
      "total_relevant": 2
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 1.0,
      "R@10": 1.0,
      "R@20": 1.0,
      "MRR": 0.5,
      "hits": 1,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.125,
      "MRR": 0.09090909090909091,
      "hits": 1,
      "total_relevant": 8
    }
  ],
  "e5_reranked": [
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.5,
      "R@20": 0.5,
      "MRR": 0.1,
      "hits": 1,
      "total_relevant": 2
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 1.0,
      "R@10": 1.0,
      "R@20": 1.0,
      "MRR": 0.5,
      "hits": 1,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.125,
      "MRR": 0.09090909090909091,
      "hits": 1,
      "total_relevant": 8
    }
  ],
  "specter": [
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 2
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.125,
      "R@10": 0.125,
      "R@20": 0.125,
      "MRR": 0.2,
      "hits": 1,
      "total_relevant": 8
    }
  ],
  "specter_reranked": [
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 2
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 4
    },
    {
      "R@5": 0.0,
      "R@10": 0.0,
      "R@20": 0.0,
      "MRR": 0.0,
      "hits": 0,
      "total_relevant": 1
    },
    {
      "R@5": 0.125,
      "R@10": 0.125,
      "R@20": 0.125,
      "MRR": 0.5,
      "hits": 1,
      "total_relevant": 8
    }
  ],
  "queries": [
    {
      "query": "Introduction Transformer is widely used in natural language processing due to its high training efficiency and superior capability in capturing long-distance dependencies. Building on top of them, mod...",
      "num_relevant": 1
    },
    {
      "query": "Introduction Transformer is widely used in natural language processing due to its high training efficiency and superior capability in capturing long-distance dependencies. Building on top of them, mod...",
      "num_relevant": 1
    },
    {
      "query": "such as BERT, are able to learn powerful language representations from unlabeled text and even surpass the human performance on the challenging question answering task. However, the good performance c...",
      "num_relevant": 2
    },
    {
      "query": "question answering task. However, the good performance comes at a high computational cost. For example, a single transformer model requires more than 10G Mult-Adds in order to translate a sentence of ...",
      "num_relevant": 1
    },
    {
      "query": "computation breakdown of the transformer and observed that the computation (Mult-Adds) is dominated by the feed-forward network (FFN). We discovered that the prevailing bottleneck-structured transform...",
      "num_relevant": 1
    },
    {
      "query": "0.4 BLEU under 500M Mult-Adds and 1.2 BLEU under 100M Mult-Adds; on WMT 2014 English-French, it also achieves consistent improvements over the transformer: 1.2 BLEU under 500M Mult-Adds and 1.7 BLEU u...",
      "num_relevant": 1
    },
    {
      "query": "mobile computation resource constraints (500M Mult-Adds), our \\model demonstrates coherent improvement on three widely used machine translation datasets. With extra experiments on other tasks, \\model ...",
      "num_relevant": 4
    },
    {
      "query": "\\model offers 0.5 higher BLEU score on WMT En-De dataset under the mobile setting, saving the design cost by 20000$\\times$ in \\coo emissions. It alerts us to rethink the practicality of AutoML in term...",
      "num_relevant": 4
    },
    {
      "query": "\\paragraph{RNNs and CNNs.} Recurrent neural networks (RNNs) have prevailed various sequence modeling tasks for a long time. However, RNNs are not easy to parallelize across the sequence due to its tem...",
      "num_relevant": 1
    },
    {
      "query": "the sequence due to its temporal dependency. Recently, some work has demonstrated that RNN is not an essential component to achieve state-of-the-art performance. For instance, researchers have propose...",
      "num_relevant": 8
    }
  ],
  "metadata": {
    "num_examples": 10,
    "k": 20,
    "llm_model": "gemma3:4b",
    "timestamp": "2025-12-18T09:47:04.237100",
    "dataset": "/Users/ishaankalra/Dev/Retrieval/corpus_loaders/scholarcopilot/scholar_copilot_eval_data_1k.json"
  }
}