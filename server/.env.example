
# Dataset Path (dataset is located in server/corpus/scholarcopilot/ directory)
DATASET_DIR="corpus/scholarcopilot/scholar_copilot_eval_data_1k.json"

# Graph Visualization Output Directory
GRAPH_OUTPUT_DIR="./graphs"

# LLM API Keys (for reranking and DSPy picker)
OPENAI_API_KEY="your_openai_api_key"

# Hugging Face Token (for model downloads)
hf_key="your_huggingface_token"

# ============================================================================
# LLM Reranker Configuration
# ============================================================================

# Inference Engine: Choose how to run the local LLM for reranking
# Options:
#   - ollama: Use Ollama (fast, easy setup, good for local development)
#   - huggingface: Use HuggingFace Transformers (best for GPU clusters without Ollama)
#   - openai: Use OpenAI API (cloud-based, requires API key)
INFERENCE_ENGINE=ollama

# Local Model Configuration
# For Ollama: model name (e.g., "gemma3:4b", "qwen3:8b", "mistral:7b", "llama3.1:8b")
# For HuggingFace: model path/name (e.g., "meta-llama/Llama-3.2-3B-Instruct", "google/gemma-2-2b-it")
LOCAL_LLM="gemma3:4b"

# OpenAI Reranker (alternative to local models)
# Set USE_OPENAI_RERANKER=true to use OpenAI instead of local inference
USE_OPENAI_RERANKER=false
# OpenAI model to use for reranking
OPENAI_RERANKER_MODEL=gpt-5-mini-2025-08-07

# ============================================================================
# DSPy Picker Configuration (optional - disabled by default)
# ============================================================================

# Enable DSPy citation picker (set to "true", "1", "yes", or "y" to enable)
ENABLE_DSPY_PICKER=false

# DSPy Model Configuration
DSPY_MODEL=gpt-5-mini-2025-08-07    # Model to use (default: gpt-5-mini-2025-08-07)
# Note: GPT-5 models don't support custom temperature, using default
DSPY_MAX_TOKENS=800                 # Max tokens (default: 800)
DSPY_MODULE=simple                  # Module type: simple, query, rerank, verify, ensemble (default: simple)
DSPY_TOP_N=10                       # Number of candidates to consider (default: 10)

# Note: When ENABLE_DSPY_PICKER=true, you must have OPENAI_API_KEY (or other LLM API key) configured

# ============================================================================
# DSPy-Optimized LLM Reranker Prompt
# ============================================================================
# Use DSPy-generated prompt for LLM reranking (from preliminary 10-citation optimization)
USE_DSPY_PROMPT=false

# ============================================================================
# DSPy Optimization (for training - see README "DSPy Optimization" section)
# ============================================================================
# To run DSPy optimization for improving Recall@k performance:
#   1. Set OPENAI_API_KEY (required - optimization limited to OpenAI models)
#   2. Prepare training data: uv run python src/agents/formulators/dspy_prompt_generator/data_prep.py
#   3. Run optimization: cd src/agents/formulators/dspy_prompt_generator && ./run_optimization.sh
# See: server/src/agents/formulators/dspy_prompt_generator/README.md for details