{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb14b132",
   "metadata": {},
   "source": [
    "# Agent that retrieves papers from the Internet based on certain keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52dcb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, random, json, base64\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from browser_use import Agent, BrowserSession, BrowserProfile, Controller, ActionResult\n",
    "from browser_use.browser.types import Page\n",
    "from browser_use.llm import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d106cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from browser_use.file_system import InMemoryFileSystem\n",
    "load_dotenv()\n",
    "\n",
    "doi = '10.1016/j.ijggc.2012.07.024' # This is a sample DOI showing how the system works.\n",
    "\n",
    "DOWNLOADS_DIR = Path(\"./downloads/\").expanduser()\n",
    "DOWNLOADS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-2025-04-14\")\n",
    "\n",
    "profile = BrowserProfile(\n",
    "    stealth=True,\n",
    "    wait_between_actions=0.5,\n",
    "    minimum_wait_page_load_time=0.25,\n",
    "    wait_for_network_idle_page_load_time=2.5,\n",
    "    maximum_wait_page_load_time=8,\n",
    "    downloads_path=str(DOWNLOADS_DIR),\n",
    "    user_agent=(\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"),\n",
    "    headless=False,          # keep headful; we’ll use CDP not page.pdf()\n",
    "    slow_mo=120,\n",
    "    timezone_id=\"Asia/Kolkata\",\n",
    "    locale=\"en-US\",\n",
    ")\n",
    "\n",
    "browser_session = BrowserSession(\n",
    "    executable_path=\"/Applications/Brave Browser.app/Contents/MacOS/Brave Browser\",\n",
    "    user_data_dir=str(Path(\"~/.config/browseruse/profiles/default\").expanduser()),\n",
    "    accept_downloads=True,\n",
    "    headless=False,\n",
    "    browser_profile=profile,\n",
    "    # optional: [\"--kiosk-printing\",\"--disable-print-preview\"] if you ever do window.print()\n",
    ")\n",
    "\n",
    "# ---------- Output State ----------\n",
    "\n",
    "class ResearchPaper(BaseModel):\n",
    "\tauthors: str\n",
    "\tpublish_date: str\n",
    "\ttitle: str\n",
    "\tdoi: str\n",
    "\tpaper_platform: str\n",
    "\tpdf_file_path: str\n",
    "\n",
    "# ---------- Controller ----------\n",
    "\n",
    "controller = Controller(output_model=ResearchPaper)\n",
    "\n",
    "# ---------- Utils ----------\n",
    "async def _close_modal_if_present(page: Page, selector=\"button[aria-label='close window']\"):\n",
    "    if await page.locator(selector).count():\n",
    "        await page.locator(selector).first.click()\n",
    "        await page.wait_for_timeout(300)\n",
    "\n",
    "async def _ensure_full_render(page: Page, pages_to_scroll=35):\n",
    "    # crude: scroll down chunk by chunk to trigger lazy loads\n",
    "    for _ in range(pages_to_scroll):\n",
    "        await page.mouse.wheel(0, 1200)\n",
    "        await page.wait_for_timeout(random.randint(150, 350))\n",
    "\n",
    "# ---------- Custom Actions ----------\n",
    "class SavePagePDFParams(BaseModel):\n",
    "    filename: str | None = None\n",
    "    print_background: bool = True\n",
    "    margin_mm: int = 10\n",
    "\n",
    "@controller.action(\"save page as pdf\", param_model=SavePagePDFParams)\n",
    "async def save_page_as_pdf(params: SavePagePDFParams, page: Page) -> ActionResult:\n",
    "    await _close_modal_if_present(page)\n",
    "    await _ensure_full_render(page)   # load lazy stuff\n",
    "    # Use CDP printToPDF\n",
    "    cdp = await page.context.new_cdp_session(page)\n",
    "    margins_in = params.margin_mm / 25.4\n",
    "    pdf_resp = await cdp.send(\"Page.printToPDF\", {\n",
    "        \"printBackground\": params.print_background,\n",
    "        \"displayHeaderFooter\": False,\n",
    "        \"marginTop\": margins_in,\n",
    "        \"marginBottom\": margins_in,\n",
    "        \"marginLeft\": margins_in,\n",
    "        \"marginRight\": margins_in,\n",
    "        \"scale\": 1.0\n",
    "    })\n",
    "    data = base64.b64decode(pdf_resp[\"data\"])\n",
    "    fname = params.filename or \"article_page_capture.pdf\"\n",
    "    path = DOWNLOADS_DIR / fname\n",
    "    path.write_bytes(data)\n",
    "    return ActionResult(extracted_content=json.dumps({\"pdf_file_path\": str(path)}))\n",
    "\n",
    "\n",
    "class DownloadParams(BaseModel):\n",
    "    selector: str | None = None   # CSS to click (preferred)\n",
    "    url: str | None = None        # direct PDF URL (fallback)\n",
    "    filename: str | None = None   # override final filename\n",
    "\n",
    "\n",
    "@controller.action(\"download pdf\", param_model=DownloadParams)\n",
    "async def download_pdf(params: DownloadParams, page: Page) -> ActionResult:\n",
    "    \"\"\"\n",
    "    Try to download a PDF either by clicking a selector (best for sites with blob URLs or auth)\n",
    "    or by fetching a direct URL. Returns {\"pdf_file_path\": \"<abs path>\"} on success.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        await _close_modal_if_present(page)\n",
    "\n",
    "        # --- Helper to persist playwright Download object ---\n",
    "        async def _save_download(d, override_name: str | None):\n",
    "            suggested = d.suggested_filename or \"download.pdf\"\n",
    "            fname = override_name or suggested\n",
    "            target = DOWNLOADS_DIR / fname\n",
    "            await d.save_as(target)\n",
    "            return target\n",
    "\n",
    "        # --- 1) Selector click path (uses Playwright's download hook) ---\n",
    "        if params.selector:\n",
    "            try:\n",
    "                # Ensure element exists & is visible\n",
    "                locator = page.locator(params.selector).first\n",
    "                await locator.wait_for(state=\"visible\", timeout=5_000)\n",
    "\n",
    "                async with page.expect_download(timeout=15_000) as dl_info:\n",
    "                    await locator.click()\n",
    "                download = await dl_info.value\n",
    "                saved = await _save_download(download, params.filename)\n",
    "                return ActionResult(extracted_content=json.dumps({\"pdf_file_path\": str(saved)}))\n",
    "            except Exception as e:\n",
    "                # fall through to other strategies\n",
    "                pass\n",
    "\n",
    "        # --- 2) If we have a direct URL, try a programmatic fetch ---\n",
    "        if params.url:\n",
    "            try:\n",
    "                # Prefer Playwright's built-in request context (inherits cookies/session)\n",
    "                resp = await page.context.request.get(params.url)\n",
    "                if not resp.ok:\n",
    "                    raise RuntimeError(f\"GET {params.url} -> {resp.status}\")\n",
    "                body = await resp.body()\n",
    "                # Crude content-type check\n",
    "                ctype = resp.headers.get(\"content-type\", \"\")\n",
    "                if \"pdf\" not in ctype.lower() and not params.url.lower().endswith(\".pdf\"):\n",
    "                    # Still save, but warn\n",
    "                    pass\n",
    "\n",
    "                fname = params.filename or Path(params.url).name or \"file.pdf\"\n",
    "                target = DOWNLOADS_DIR / fname\n",
    "                target.write_bytes(body)\n",
    "                return ActionResult(extracted_content=json.dumps({\"pdf_file_path\": str(target)}))\n",
    "            except Exception:\n",
    "                # final fallback below\n",
    "                pass\n",
    "\n",
    "        # --- 3) Last resort: force a download via DOM (anchor.click) + expect_download ---\n",
    "        try:\n",
    "            if params.url:\n",
    "                async with page.expect_download(timeout=15_000) as dl_info:\n",
    "                    await page.evaluate(\n",
    "                        \"(url)=>{const a=document.createElement('a');a.href=url;a.download='';\"\n",
    "                        \"document.body.appendChild(a);a.click();a.remove();}\", params.url\n",
    "                    )\n",
    "                download = await dl_info.value\n",
    "                saved = await _save_download(download, params.filename)\n",
    "                return ActionResult(extracted_content=json.dumps({\"pdf_file_path\": str(saved)}))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return ActionResult(error=\"Could not download PDF via selector or url.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return ActionResult(error=f\"download_pdf failed: {e!r}\")\n",
    "\n",
    "class ResetTabsParams(BaseModel):\n",
    "    url: str = \"about:blank\"\n",
    "\n",
    "@controller.action(\"reset to single tab\", param_model=ResetTabsParams)\n",
    "async def reset_tabs(params: ResetTabsParams, page: Page) -> ActionResult:\n",
    "    ctx = page.context\n",
    "    new_page = await ctx.new_page()\n",
    "    await new_page.goto(params.url)\n",
    "    await new_page.bring_to_front()\n",
    "\n",
    "    for p in ctx.pages[:]:\n",
    "        if p is not new_page and not p.is_closed():\n",
    "            try:\n",
    "                await p.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return ActionResult(extracted_content=json.dumps({\"active_url\": new_page.url}))\n",
    "\n",
    "from typing import Literal, List, Optional\n",
    "class MuteUIParams(BaseModel):\n",
    "    patterns: List[str] = [\"download pdf\", \"view pdf\"]   # phrases to kill\n",
    "    mode: Literal[\"hide\", \"remove\"] = \"hide\"             # CSS hide or DOM remove\n",
    "    min_repeat: int = 3                                   # auto-detect spam if repeated ≥ N times\n",
    "    tag_filter: Optional[List[str]] = [\"a\",\"button\",\"div\",\"span\"]  # which tags to scan\n",
    "\n",
    "@controller.action(\"mute noisy elements\", param_model=MuteUIParams)\n",
    "async def mute_noisy(params: MuteUIParams, page: Page) -> ActionResult:\n",
    "    # Build JS\n",
    "    js_fn = \"\"\"\n",
    "            (cfg) => {\n",
    "            const tags = (cfg.tag_filter || [\"a\",\"button\",\"div\",\"span\"]);\n",
    "            const nodes = [...document.querySelectorAll(tags.join(','))];\n",
    "            const norm = t => t.trim().toLowerCase().replace(/\\\\s+/g,' ');\n",
    "            const counts = {};\n",
    "            nodes.forEach(n => {\n",
    "                const text = norm(n.textContent || \"\");\n",
    "                if (text.length < 3) return;\n",
    "                counts[text] = (counts[text] || 0) + 1;\n",
    "            });\n",
    "\n",
    "            const patternRegexes = (cfg.patterns || []).map(p => new RegExp(p, 'i'));\n",
    "            const isPatternHit = t => patternRegexes.some(r => r.test(t));\n",
    "\n",
    "            const spamTexts = new Set(\n",
    "                Object.entries(counts)\n",
    "                .filter(([t,c]) => c >= cfg.min_repeat || isPatternHit(t))\n",
    "                .map(([t]) => t)\n",
    "            );\n",
    "\n",
    "            const removed = [];\n",
    "            nodes.forEach(n => {\n",
    "                const t = norm(n.textContent || \"\");\n",
    "                if (spamTexts.has(t)) {\n",
    "                if (cfg.mode === \"remove\") n.remove();\n",
    "                else n.style.setProperty(\"display\",\"none\",\"important\");\n",
    "                if (removed.length < 50) removed.push(t);\n",
    "                }\n",
    "            });\n",
    "            return removed;\n",
    "            }\n",
    "            \"\"\".strip()\n",
    "    removed = await page.evaluate(js_fn, params.dict())\n",
    "    return ActionResult(extracted_content=json.dumps({\"muted_samples\": removed}))\n",
    "\n",
    "\n",
    "# ---------- Hook ----------\n",
    "async def human_pause(agent: Agent):\n",
    "    await asyncio.sleep(random.uniform(0.4, 1.6))\n",
    "\n",
    "# ---------- Task ----------\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You have these custom actions available:\n",
    "- \"reset to single tab\" -> params: {{ \"url\": \"about:blank\" }}\n",
    "- \"save page as pdf\"   -> params: {{ \"filename\": str|None, \"print_background\": bool, \"margin_mm\": int }}\n",
    "- \"download pdf\"       -> params: {{ \"selector\": str|None, \"url\": str|None, \"filename\": str|None }}\n",
    "\n",
    "Follow the steps EXACTLY:\n",
    "\n",
    "0. **Immediately call** \"reset to single tab\" with {{\"url\":\"about:blank\"}}. Do this before any browsing.\n",
    "1. Navigate to {doi}.\n",
    "2. Extract the following from the HTML page (not the PDF):\n",
    "   - \"title\": string\n",
    "   - \"authors\": array of strings\n",
    "   - \"abstract\": string\n",
    "3. **Do NOT click “View PDF”.** Stay on the HTML article page.\n",
    "4. Scroll the entire article to trigger all lazy-loaded content (images, references, etc.).\n",
    "5. Call \"save page as pdf\" with:\n",
    "   {{\n",
    "     \"filename\": \"`use the title of the paper you extracted above`.pdf\",\n",
    "     \"print_background\": true,\n",
    "     \"margin_mm\": 10\n",
    "   }}\n",
    "   This should capture the fully rendered HTML page.\n",
    "6. If (and only if) there is a way to get a *real* PDF file (button/link) without violating step 3:\n",
    "   - Prefer selector click: call \"download pdf\" with {{\"selector\": \"<css selector>\", \"filename\": \"download.pdf\"}}\n",
    "   - Otherwise if you see a direct .pdf URL, call \"download pdf\" with {{\"url\": \"<pdf_url>\", \"filename\": \"download.pdf\"}}\n",
    "   Skip this if neither is clearly available.\n",
    "7. Final output: return a single JSON object with keys:\n",
    "   {{\n",
    "     \"title\": \"...\",\n",
    "     \"authors\": [...],\n",
    "     \"abstract\": \"...\",\n",
    "     \"pdf_file_path_html\": \"<from save page as pdf>\",\n",
    "     \"pdf_file_path_download\": \"<from download pdf or null if not downloaded>\"\n",
    "   }}\n",
    "\n",
    "Rules:\n",
    "- Always call \"reset to single tab\" first.\n",
    "- Never click \"View PDF\".\n",
    "- Be concise in tool outputs; no extraneous text, just JSON values.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(\n",
    "        task=prompt,\n",
    "        llm=llm,\n",
    "        browser_session=browser_session,\n",
    "        controller=controller,\n",
    "        # file_system=InMemoryFileSystem()\n",
    "    )\n",
    "    result = await agent.run(on_step_start=human_pause, max_steps=40)\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await (main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee71058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
