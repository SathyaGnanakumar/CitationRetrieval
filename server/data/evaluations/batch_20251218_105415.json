{
  "query": "Introduction Training modern Large Language Models (LLMs) with billions of parameters requires thousands of GPUs running in parallel. This is necessary to load the model and optimizer parameters in memory and reach the mini-batch size in the millions of tokens used to train them<|cite_0|>, relying on a distributed version of",
  "paper_id": "2406.02613",
  "retrieved_ids": [
    "minaee2024large",
    "kaddour2023challenges",
    "jordan_chinchilla_2022",
    "Zhao2023ASO",
    "survey2",
    "shoeybi2020megatronlm",
    "zheng2020distdgl",
    "naveed2024comprehensivellms",
    "sriram2022towards",
    "qin2024large",
    "mmllms1",
    "levy2024same",
    "shnitzer2023large",
    "llmsurvey3",
    "Zero1",
    "makatura2023large",
    "miao2023towards",
    "Hu:2022:LLR",
    "du2022glamefficientscalinglanguage",
    "ref:med1",
    "jiang2023llmlingua",
    "pang2024anchor",
    "xiao2024smoothquant",
    "Zerooffload",
    "kim2023memoryefficient",
    "malladi2023fine",
    "chen2023accelerating",
    "hu2024minicpm",
    "mehta2024openelm",
    "huang2019gpipe",
    "xia2023sheared",
    "meta-mm-scalinglaw",
    "narayanan2021memory",
    "svirschevski2024specexec",
    "ioffe2015batch",
    "rajbhandari2021zero",
    "britz2017massive",
    "Zhang2022OPTOP",
    "owq",
    "gshard",
    "zhang2024recurrentdrafterfastspeculative",
    "namburi2023cost",
    "shazeer2018mesh",
    "liu2019roberta",
    "chen23l_interspeech",
    "fu2024break",
    "jamba",
    "stich2018local",
    "shayer2017learning",
    "pham2021combined",
    "zafrir2019q8bert"
  ],
  "relevant_ids": [
    "Dutta2021",
    "mcmahan17a",
    "Wang2020SlowMo",
    "ortiz2021tradeoffs",
    "COCOSGD2019",
    "sun2024co",
    "OverlapSGD2020",
    "Zero1",
    "mishchenko2022asynchronous",
    "loshchilov2018decoupled",
    "touvron2023llama",
    "maranjyan2022gradskip",
    "KingBa15",
    "PytorchDDP2020",
    "EASGD2015",
    "stich2018local",
    "Konecn2016FederatedOD",
    "diskin2021distributed",
    "Zerooffload"
  ],
  "metrics": {
    "R@5": 0.0,
    "R@10": 0.0,
    "R@20": 0.05263157894736842,
    "MRR": 0.06666666666666667,
    "hits": 3,
    "total_relevant": 19
  },
  "score": 0.02,
  "timestamp": "2025-12-18T10:54:15.358615"
}