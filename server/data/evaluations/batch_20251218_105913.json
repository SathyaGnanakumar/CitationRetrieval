{
  "query": "Introduction Large language models have garnered considerable attention from both academic and industrial communities, providing artificial intelligence with the capability to adeptly integrate into myriad downstream applications. The deployment of large language models typically involves two discernible phases. As depicted in Figure~\\ref{fig:overall}, the initial stage focuses on pre-training the model",
  "paper_id": "2401.14027",
  "retrieved_ids": [
    "minaee2024large",
    "kaddour2023challenges",
    "naveed2024comprehensivellms",
    "Zhao2023ASO",
    "gpt_summary",
    "sahoo2024systematic",
    "laskar2024systematic",
    "wang2024large",
    "xi2023rise",
    "ref:med1",
    "survey2",
    "qu2024tool",
    "ref:edu1",
    "llmsurvey2",
    "alkhamissi2022review",
    "wang2023survey",
    "llmsurvey",
    "zhao2023chatbridge",
    "survey1",
    "wang2023knowledge",
    "shu2023llasm",
    "peng2023kosmos",
    "rae2021scaling",
    "ref:med3",
    "miao2023towards",
    "ref:finalcialgpt2",
    "Gao2023RetrievalAugmentedGF",
    "gunter2024apple",
    "ref:ragsurvey3",
    "zhang2023speechgpt",
    "ahuja2023mega",
    "Pan2023AutomaticallyCL",
    "ahuja-etal-2023-mega",
    "solaiman2019release",
    "sink",
    "ref:ragsurvey2",
    "llmsurvey3",
    "wolf2019huggingface",
    "b3",
    "li2022mplug",
    "bai2023qwen",
    "wang2022lilt",
    "guo2023black",
    "gupta2024model",
    "tan2021survey"
  ],
  "relevant_ids": [
    "chen-et-al:scheme",
    "li-et-al:scheme",
    "ding-et-al:scheme",
    "ye-et-al:scheme",
    "cai-et-al:scheme",
    "wang2022does",
    "brown-et-al:scheme",
    "houlsby-et-al:scheme",
    "touvron2023llama",
    "devlin2018bert",
    "rebuffi-et-al:scheme",
    "wang-et-al:scheme",
    "zhou-et-al:scheme",
    "Muandet-et-al:scheme",
    "zhou-et-al:scheme1",
    "ji-et-al:scheme",
    "kumar-et-al:scheme",
    "croce-et-al:scheme",
    "hu-et-al:scheme",
    "wortsman-et-al:scheme",
    "shi-et-al:scheme",
    "luo-et-al:scheme",
    "t5raffel2020exploring",
    "zaken-et-al:scheme"
  ],
  "metrics": {
    "R@5": 0.0,
    "R@10": 0.0,
    "R@20": 0.0,
    "MRR": 0.0,
    "hits": 0,
    "total_relevant": 24
  },
  "score": 0.0,
  "timestamp": "2025-12-18T10:59:13.154553"
}