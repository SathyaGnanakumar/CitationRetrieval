{
  "query": "Introduction \\begin{figure}[!t] \\centering \\includegraphics[width=\\linewidth]{figures/flops-acc.pdf} \\caption{Performance comparisons on ImageNet. With comparable GFLOPs (1.25 vs. 1.39), our proposed Scale HVT-Ti-4 surpasses DeiT-Ti by 3.03\\% in Top-1 accuracy. } \\label{fig:flops-acc} \\vspace{-10pt} \\end{figure} Equipped with the self-attention mechanism that has strong capability of capturing long-range dependencies, Transformer<|cite_0|> based models have achieved significant breakthroughs in",
  "paper_id": "2103.10619",
  "retrieved_ids": [
    "sasa",
    "chen2020pre",
    "T2T",
    "t2tformer",
    "uniformer",
    "yang2021lite",
    "wang2021notallimage16",
    "touvron2021going",
    "wang2023closer",
    "dat",
    "suchengCVPR22",
    "zhai2022scaling",
    "meng2022adavit",
    "wu2021pale",
    "ref17",
    "resformer",
    "yao2023dual",
    "mao2022towards",
    "transformertts",
    "tu2022maxvit",
    "zhou2021deepvit",
    "zhang2022vitaev2",
    "zhou2022understanding",
    "tnt",
    "wu2021rethinking",
    "nat",
    "guo2022cmt",
    "li2022efficientformer",
    "lin2022super",
    "Xie:2021:SSE",
    "shaker2022unetr++",
    "wu2021cvt",
    "yao2022wave",
    "chen2023pixartalpha",
    "liu2021swin",
    "simmim",
    "dong2021cswin",
    "pan202iared2",
    "xie2021fignerf",
    "zhang2022parcnet",
    "li2016ternary",
    "inceptionformer",
    "tang2023elasticvit",
    "localmamba",
    "fang2020densely",
    "efficientvmamba",
    "liu2021video",
    "Yan2021ConTNetWN",
    "tang2022patchslim",
    "yu2022metaformer",
    "li2024llavamed"
  ],
  "relevant_ids": [
    "sparse_attn",
    "peg",
    "tan2019efficientnet",
    "dedetr",
    "Devlin2019BERTPO",
    "t2tformer",
    "distillbert",
    "pvt",
    "simonyan2014very",
    "cbert",
    "vit",
    "jiao2019tinybert",
    "lin2017feature",
    "funnel",
    "peng2021random",
    "lrnet",
    "vistr",
    "performer",
    "li2017pruning",
    "powerbert",
    "maxdlab",
    "axial_attn",
    "rae2020compressive",
    "katharopoulos2020transformers",
    "deit",
    "transformer",
    "resnet",
    "selfconv",
    "ternarybert",
    "sasa",
    "fqt",
    "dai2019transformer",
    "hat",
    "axiallab",
    "reformer",
    "botnet",
    "linformer",
    "detr",
    "sixteen_heads"
  ],
  "metrics": {
    "R@5": 0.05128205128205128,
    "R@10": 0.05128205128205128,
    "R@20": 0.05128205128205128,
    "MRR": 1.0,
    "hits": 2,
    "total_relevant": 39
  },
  "score": 0.33589743589743587,
  "timestamp": "2025-12-18T10:51:47.492242"
}