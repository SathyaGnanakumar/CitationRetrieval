{
  "query": "Introduction In reinforcement learning (RL), the agent sequentially interacts with the environment and receives reward from it. In many real-world RL problems, the reward function is manually designed to encourage the desired behavior of the agent. Thus, engineers have to change the reward function time by time and train the",
  "paper_id": "2110.06394",
  "retrieved_ids": [
    "dulac2020empirical",
    "kaelbling1996reinforcement",
    "zhu2020ingredients",
    "aubret-survey-2019",
    "lin2023survey",
    "janner2021offline",
    "li2017deep",
    "adeniji2023language",
    "li2023survey",
    "yu-explainable-2023",
    "reddy2019sqil",
    "qin2022neorl",
    "casper2023open",
    "lambert2023history",
    "florensa2018automatic",
    "lee2021pebble",
    "vecerik2017leveraging",
    "eysenbach2017leave",
    "learningtolearn",
    "liu2018reinforcement",
    "eysenbach2020off",
    "sharma2020emergent",
    "sharma2022state",
    "Christiano2017DeepRL",
    "cabi2020scaling",
    "zhao2020mutual",
    "peng2019advantage",
    "kim2022automating",
    "sharma2021autonomous",
    "wang2020reward",
    "zhang2018study",
    "fujimoto2021minimalist",
    "sharma2021vaprl",
    "toromanoff2020end",
    "eureka",
    "jin2020reward",
    "eysenbach2021maximum",
    "huang2022efficient",
    "burda2018large",
    "brandfonbrener2022does",
    "Pang2022RewardGI",
    "wang2020SERL",
    "zhang2020automatic",
    "lu2020reset",
    "pathak2017curiosity",
    "Schulman2017",
    "Zhuang2021ConsequencesOM",
    "imagine_explore",
    "her"
  ],
  "relevant_ids": [
    "liu2020sharp",
    "ayoub2020model",
    "wang2020reward",
    "kaufmann2020adaptive",
    "zanette2020provably",
    "zhang2020nearly",
    "jin2020reward",
    "modi2020sample",
    "zanette2020frequentist",
    "zhou2020provably",
    "zanette2019tighter",
    "jia2020model",
    "menard2020fast",
    "yang2019sample",
    "zanette2020learning",
    "zhou2020nearly",
    "jin2020provably",
    "wang2019optimism"
  ],
  "metrics": {
    "R@5": 0.0,
    "R@10": 0.0,
    "R@20": 0.0,
    "MRR": 0.03333333333333333,
    "hits": 2,
    "total_relevant": 18
  },
  "score": 0.01,
  "timestamp": "2025-12-18T10:57:00.670382"
}