{
  "query": "Introduction Large Language Models~(LLMs) have achieved remarkable success in various natural language processing tasks, such as language understanding, reasoning, and generation, demonstrating superior performance and adaptability<|cite_0|>. However, the rapid growth in model size, with state-of-the-art LLMs containing billions of parameters, poses significant challenges to computational resources and memory consumption<|cite_1|>. The",
  "paper_id": "2406.08155",
  "retrieved_ids": [
    "kaddour2023challenges",
    "naveed2024comprehensivellms",
    "minaee2024large",
    "guo2024large",
    "Zhao2023ASO",
    "laskar2024systematic",
    "survey2",
    "Zhu2023LargeLM",
    "mmllms2",
    "xie2023translating",
    "ref:financialgpt",
    "qin2024large",
    "miao2023towards",
    "ref:edu1",
    "ref:med1",
    "hu2024rankprompt",
    "wang2023knowledge",
    "ref:ragsurvey2",
    "mmllms1",
    "Gao2023RetrievalAugmentedGF",
    "ref:ragsurvey7",
    "model_compression",
    "asai2024reliable",
    "llmsurvey3",
    "huang2023languages",
    "yuan2024llminferenceunveiledsurvey",
    "zheng2024",
    "du2022glamefficientscalinglanguage",
    "chia2024instructeval",
    "zhang2023FinEvalChineseFinancial",
    "jin2024comprehensive",
    "makatura2023large",
    "kim2023memoryefficient",
    "ref:med3",
    "mirzadeh2023relustrikesbackexploiting",
    "yu2023metamath",
    "jiang2023scaling",
    "ganesh2020compressing",
    "pang2024anchor",
    "chen2023videollm",
    "shao2023omniquant",
    "ahuja-etal-2023-mega",
    "tian2024gnp",
    "ahuja2023mega",
    "yu2024melo"
  ],
  "relevant_ids": [
    "aminabadi2022deepspeed",
    "pan2023smoothquant+",
    "dai2024deepseekmoe",
    "li2024merge",
    "krajewski2024scaling",
    "liu2023llm",
    "artetxe2022efficient",
    "kaplan2020scaling",
    "jiang2024mixtral",
    "lin2024awq",
    "brown2020language",
    "openai2024gpt4",
    "rajbhandari2022deepspeedmoe",
    "jiang2023mistral",
    "frantar2023optimal",
    "touvron2023llama",
    "xiao2024smoothquant",
    "frantar2023gptq",
    "fedus2022switch",
    "shoeybi2020megatronlm",
    "chen2022taskspecific",
    "shazeer2017outrageously",
    "sharify2024combining"
  ],
  "metrics": {
    "R@5": 0.0,
    "R@10": 0.0,
    "R@20": 0.0,
    "MRR": 0.0,
    "hits": 0,
    "total_relevant": 23
  },
  "score": 0.0,
  "timestamp": "2025-12-18T10:53:50.328656"
}