{
  "query": "Introduction The bias-variance trade-off in classical learning theory suggests that models with large capacity to minimize the empirical risk to almost zero usually yield poor generalization performance. However, this is not the case of modern deep neural networks (DNNs): Zhang \\emph{et al.}~\\shortcite{zhang2017} showed that over-parameterized networks have powerful expressivity to",
  "paper_id": "2004.13954",
  "retrieved_ids": [
    "Yang2020",
    "Neyshabur2019TowardsUT",
    "zhang2018mixup",
    "zou2019improved",
    "zhang2017",
    "zhang2019type",
    "Geiger2020",
    "nagarajan2019uniform",
    "huang2020self",
    "allen2018convergence",
    "arora2019fine",
    "rosenfeld2020risks",
    "ortiz2021tradeoffs",
    "Cao2019",
    "Arpit2017",
    "Dinh2017",
    "liu2021orthogonal",
    "maddox2020rethinking",
    "du2018gradientA",
    "oymak2020towards",
    "liu2022loss",
    "jin2022pruning",
    "simsekli2020hausdorff",
    "liu2021learning",
    "song2019understanding",
    "dynamicrepara",
    "lafon2024understanding",
    "zou2018stochastic",
    "xu2021representation",
    "lee2019wide",
    "haochen2022theoretical",
    "uhlich2019mixed",
    "bounds",
    "zhou2019nonvacuous",
    "GCE",
    "mukhoti2020calibrating",
    "mvsgcn",
    "Xu2019a",
    "10.1145/3394486.3403192",
    "schaeffer2023double",
    "you2020shiftaddnet",
    "chen2021iterative",
    "liang2018understanding",
    "zhu2017prune",
    "andriushchenko2022towards",
    "anil_conv",
    "yu2019playing",
    "singla2021curvature"
  ],
  "relevant_ids": [
    "Arpit2017",
    "Rahaman2019",
    "Geiger2020",
    "Xu2019a",
    "Yang2020",
    "Nakkiran2020",
    "Zhang2020",
    "Pascanu2014",
    "Poole2016",
    "Ronen2019",
    "Montufar2014",
    "zhang2017",
    "Kalimeris2019",
    "Arora2018",
    "Cao2019",
    "Xu2019"
  ],
  "metrics": {
    "R@5": 0.125,
    "R@10": 0.1875,
    "R@20": 0.3125,
    "MRR": 1.0,
    "hits": 6,
    "total_relevant": 16
  },
  "score": 0.40625,
  "timestamp": "2025-12-18T10:48:10.981163"
}