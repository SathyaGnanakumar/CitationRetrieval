{
  "query": "Introduction Transformer<|cite_0|> is widely used in natural language processing due to its high training efficiency and superior capability in capturing long-distance dependencies. Building on top of them, modern state-of-the-art models, such as BERT<|cite_1|>, are able to learn powerful language representations from unlabeled text and even surpass the human performance on",
  "paper_id": "2004.11886",
  "retrieved_ids": [
    "llmsurvey2",
    "kalyan2021ammus",
    "tay2020efficient",
    "ganesh2020compressing",
    "TRL",
    "wolf2019huggingface",
    "lan2019albert",
    "minaee2024large",
    "jiao2019tinybert",
    "li2020sentence",
    "jiao20tinybert",
    "devlin2019bert",
    "Devlin:2019uk",
    "dai2019transformer",
    "funnel",
    "jin2020bert",
    "wang2020cluster",
    "bondarenko2021understanding",
    "wang-etal-2019-learning",
    "han2020survey",
    "du2022glamefficientscalinglanguage",
    "distillbert",
    "lite_transformer",
    "pappagari2019hierarchical",
    "conformer",
    "mehta_gss_iclr_2023",
    "sun2019fine",
    "pixelbert",
    "tsai2019multimodal",
    "yang2017breaking",
    "kobayashi-etal-2020-attention",
    "he2020realformer",
    "ao2021speecht5",
    "geng2022multimodal",
    "yan2021consert",
    "guo2019star",
    "zhang2019ernie",
    "fang2020cert",
    "zafrir2019q8bert",
    "yang2019xlnet",
    "liu2019text",
    "Mees2022WhatMI",
    "phang2018sentence",
    "qiu2020blockwise",
    "uniformer",
    "zhen2022cosformer",
    "mrkvsic2017neural"
  ],
  "relevant_ids": [
    "Krishnamoorthi:2018wr",
    "Wu:2016wt",
    "Liu:2017wj",
    "Vaswani:2017ul",
    "So:2019wo",
    "Han:2015vn",
    "Ott:2018ui",
    "He:2018vj",
    "Devlin:2019uk",
    "Sukhbaatar:2019augmenting",
    "liu2019point",
    "Luong:2015wx",
    "Cai:2019ui",
    "Zhu:2017wy",
    "Wang:2019tj",
    "Shaw:2018wh",
    "Gehring:2017tva",
    "Kaiser:2018wo",
    "Han:2016uf",
    "Wu:2019tk",
    "Zoph:2017uo",
    "Wu:2019wt",
    "He:2017vq",
    "Sutskever:2014tya",
    "Child:2019sparsetransformer",
    "Strubell:2019uv",
    "Pham:2018tl",
    "Ahmed:2017tm",
    "Yang:2018tp",
    "Paulus:2018to",
    "Bahdanau:2015vz",
    "Zoph:2018ta",
    "Tan:2018vw",
    "li2020gan",
    "Courbariaux:2016tm",
    "Chen:2018vf",
    "Sukhbaatar:2019adaptive",
    "Kalchbrenner:2016vf",
    "Liu:2019tx"
  ],
  "metrics": {
    "R@5": 0.0,
    "R@10": 0.0,
    "R@20": 0.02564102564102564,
    "MRR": 0.07692307692307693,
    "hits": 1,
    "total_relevant": 39
  },
  "score": 0.023076923076923078,
  "timestamp": "2025-12-18T10:50:47.637936"
}