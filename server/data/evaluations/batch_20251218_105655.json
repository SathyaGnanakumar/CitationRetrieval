{
  "query": "Introduction \\label{introduction} Convolutional Neural Networks (CNN) dominate the learning of visual representations and show effectiveness on various downstream tasks, including image classification, object detection, semantic segmentation, etc. Recently, convolution-free backbones show impressive performances on image classification. Vision Transformer (ViT)<|cite_0|> firstly shows that pure Transformer architecture can attain state-of-the-art performance when",
  "paper_id": "2110.04035",
  "retrieved_ids": [
    "kang2016object",
    "li2022ViTDet",
    "bhojanapalli2021understanding",
    "li2021can",
    "cspnet",
    "wu2021cvt",
    "han2020survey",
    "do-VTs-see-like-CNNs",
    "guo2022cmt",
    "paul2022vision",
    "vgg",
    "gu2022multi",
    "strudel2021segmenter",
    "wang2021pvt",
    "huang2022lightvit",
    "Szegedy2014",
    "li2021involution",
    "uniformer",
    "liu2022more",
    "wu2020visual",
    "naseer2021intriguing",
    "li2022nextvit",
    "ding2021diverse",
    "li2021benchmarking",
    "dosovitskiy2020vit",
    "liu2022convnet",
    "t2tformer",
    "vit",
    "farispaper",
    "peng2021conformer",
    "mao2022towards",
    "T2T",
    "bai2021transformers",
    "botnet",
    "zhou2021deepvit",
    "chu2021twins",
    "chen2022vision",
    "Lee2021ViTGANTG",
    "jiang2021transgan",
    "Yan2021ConTNetWN",
    "heo2021rethinking",
    "yang2021lite",
    "lee2022mpvit",
    "ding2023unireplknet",
    "liu2021swin",
    "Ranftl2021dpt",
    "Zheng20213DHP"
  ],
  "relevant_ids": [
    "carafe++",
    "yuan2021incorporating",
    "coco",
    "resmlp",
    "cvt",
    "lip",
    "mixer",
    "inception",
    "zhang2019shiftinvar",
    "efficientnet",
    "pvt",
    "deit",
    "vit",
    "resnet",
    "dpp",
    "convit"
  ],
  "metrics": {
    "R@5": 0.0,
    "R@10": 0.0,
    "R@20": 0.0,
    "MRR": 0.03571428571428571,
    "hits": 1,
    "total_relevant": 16
  },
  "score": 0.010714285714285713,
  "timestamp": "2025-12-18T10:56:55.933187"
}