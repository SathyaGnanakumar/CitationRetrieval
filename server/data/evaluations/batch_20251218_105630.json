{
  "query": "Introduction Self-attention-based models, especially vision transformers \\citep[ViTs; Figure \\ref{fig:vit};][]{dosovitskiy2020image}, are an alternative to convolutional neural networks (CNNs) to learn visual representations. Briefly, ViT divides an image into a sequence of non-overlapping patches and then learns inter-patch representations using multi-headed self-attention in transformers<|cite_0|>. The general trend is to increase the number",
  "paper_id": "2110.02178",
  "retrieved_ids": [
    "li2021can",
    "do-VTs-see-like-CNNs",
    "park2023self",
    "park2022vision",
    "khan2021transformers",
    "han2020survey",
    "chu2021twins",
    "li2021efficient",
    "naseer2021intriguing",
    "wang2023closer",
    "tnt",
    "zhou2022understanding",
    "Caron:2021:EPS",
    "chen2022regionvit",
    "yang2021lite",
    "dino",
    "dat",
    "lin2022cat",
    "zhou2021deepvit",
    "yao2022wave",
    "tu2022maxvit",
    "mao2022towards",
    "dosovitskiy2020vit",
    "jelassi2022vision",
    "vit",
    "lee2021vision",
    "wu2021pale",
    "xu2021vitae",
    "chen2021crossvit",
    "meng2022adavit",
    "Hong2022RepresentationSF",
    "paul2022vision",
    "mehta2021mobilevit",
    "qin2021understanding",
    "xiao2023patch-wise",
    "DUAL-VIT",
    "lee2022mpvit",
    "Lambdanetworks",
    "xcit",
    "patchesallyouneed",
    "wang2022anti",
    "suchengCVPR22",
    "gberta_2021_ICML",
    "melas2021resmlp"
  ],
  "relevant_ids": [
    "touvron2021training",
    "heo2021rethinking",
    "zhou2021deepvit",
    "vaswani2017attention",
    "tan2019efficientnet",
    "d2021convit",
    "tan2019mixconv",
    "howard2019searching",
    "ma2018shufflenet",
    "mehta2019espnetv2",
    "sandler2018mobilenetv2",
    "rao2021dynamicvit",
    "xiao2021early",
    "he2016deep",
    "dai2021coatnet",
    "ranftl2021vision",
    "wu2021cvt",
    "touvron2021going",
    "chen2017rethinking",
    "tan2019mnasnet",
    "wang2021pyramid",
    "howard2017mobilenets",
    "chollet2017xception",
    "zhong2020random",
    "srinivas2021bottleneck",
    "russakovsky2015imagenet",
    "chen2021mobile",
    "dosovitskiy2020image"
  ],
  "metrics": {
    "R@5": 0.0,
    "R@10": 0.0,
    "R@20": 0.03571428571428571,
    "MRR": 0.05263157894736842,
    "hits": 1,
    "total_relevant": 28
  },
  "score": 0.015789473684210523,
  "timestamp": "2025-12-18T10:56:30.576394"
}