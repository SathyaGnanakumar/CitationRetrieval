query_id,paper_id,true_title,context,retrieved_titles,category,corpus_size
q_23,paper_0,{Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1,"e neurons<|cite_21|> or the entire channels<|cite_22|>; others have proposed to quantize the network<|cite_23|> to accelerate the model inference. 
Recently, AutoML has also been used to automate the model compr","['{HAQ: Hardware-Aware Automated Quantization with Mixed Precision', '{HAQ: Hardware-Aware Automated Quantization with Mixed Precision', '{Neural Machine Translation by Jointly Learning to Align and Translate', '{AMC: AutoML for Model Compression and Acceleration on Mobile Devices', '{AMC: AutoML for Model Compression and Acceleration on Mobile Devices']",not_in_top_k,51
q_28,paper_1,Dynamically fused graph network for multi-hop reasoning," chemistry<|cite_1|>, social networks<|cite_2|>, computer vision, and natural language understanding<|cite_3|>. GNN assumes structured graphical inputs, for example, molecule graphs, protein-protein interaction","['Graph attention networks', 'Graph attention networks', 'Graph neural networks for social recommendation', 'Improved semantic representations from tree-structured long short-term memory networks', 'Inductive representation learning on large graphs']",not_in_top_k,38
q_29,paper_1,Semi-supervised classification with graph convolutional networks,"s have been proposed to learn graph representation,

which include Graph Convolutional Network (GCN)<|cite_4|>, GraphSage<|cite_5|>, Graph Isomorphism Network (GIN)<|cite_6|> and Graph Attention Network (GAT)<|","['Graph convolutional networks for text classification', 'How powerful are graph neural networks?', 'How powerful are graph neural networks?', 'Aspect-based sentiment classification with aspect-specific graph convolutional networks', 'Graph attention networks']",not_in_top_k,38
q_39,paper_1,Semi-supervised classification with graph convolutional networks,"
Multiple GNN variants have been proposed with different message passing algorithms. For example GCN<|cite_14|>, Graph Sage<|cite_15|>, GAT<|cite_16|>, GIN<|cite_17|>, etc. Our proposed GSN can be regarded as a ","['Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs', 'Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs', 'Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs', 'How powerful are graph neural networks?', 'How powerful are graph neural networks?']",not_in_top_k,38
q_40,paper_1,Inductive representation learning on large graphs,"have been proposed with different message passing algorithms. For example GCN<|cite_14|>, Graph Sage<|cite_15|>, GAT<|cite_16|>, GIN<|cite_17|>, etc. Our proposed GSN can be regarded as a variant of GNN. However","['Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs', 'Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs', 'Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs', 'Neural message passing for quantum chemistry', 'Graph neural networks for social recommendation']",not_in_top_k,38
