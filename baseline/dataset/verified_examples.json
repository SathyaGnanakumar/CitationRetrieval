[
  {
    "id": "21",
    "excerpt": "One reason might be the training task itself: from [CITATION] we know that ImageNet can be solved to high accuracy using only local information. In other words, it might simply suffice to integrate evidence from many local texture features rather than going through the process of integrating and classifying global shapes",
    "target_paper_title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet",
    "target_paper_url": "https://arxiv.org/pdf/1904.00760.pdf",
    "source_paper_title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
    "source_paper_url": "https://arxiv.org/pdf/1811.12231.pdf",
    "year": "2019",
    "split": "train",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "24",
    "excerpt": "To address this, [CITATION] introduced Adversarial Filtering (AF). An overview is shown in Figure 2. The key idea is to produce a dataset D which is adversarial for any arbitrary split of (D_train), (D_test)",
    "target_paper_title": "Swag: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference",
    "target_paper_url": "https://aclanthology.org/D18-1009.pdf",
    "source_paper_title": "HellaSwag: Can a Machine Really Finish Your Sentence?",
    "source_paper_url": "https://arxiv.org/pdf/1905.07830.pdf",
    "year": "2019",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "54",
    "excerpt": "A user may want to control the amount of snow on the mountain. However, it is quite difficult to describe the desired amount of snow through text. Instead, we suggest a fader control [CITATION], where the user controls the magnitude of the effect induced by a specific word, as depicted in fig. 9. ",
    "target_paper_title": "Fader networks: Manipulating images by sliding attributes",
    "target_paper_url": "https://arxiv.org/pdf/1706.00409.pdf",
    "source_paper_title": "Prompt-to-Prompt Image Editing with Cross Attention Control",
    "source_paper_url": "https://arxiv.org/pdf/2208.01626.pdf",
    "year": "2022",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "56",
    "excerpt": "The model was trained on Gaussian patches [CITATION]. Since no model weights are released, we can only include their Top-1 ImageNet-C accuracy values from their paper (and not the Top-5).",
    "target_paper_title": "Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation",
    "target_paper_url": "https://arxiv.org/pdf/1906.02611.pdf",
    "source_paper_title": "A simple way to make neural networks robust against diverse image corruptions",
    "source_paper_url": "https://arxiv.org/pdf/2001.06057.pdf",
    "year": "2020",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "59",
    "excerpt": "Our evaluation follows the protocol of [CITATION], a recent inpainting model that introduces a specialized architecture relying on Fast Fourier Convolutions [8]",
    "target_paper_title": "Resolution-robust Large Mask Inpainting with Fourier Convolutions",
    "target_paper_url": "https://arxiv.org/pdf/2109.07161.pdf",
    "source_paper_title": "High-Resolution Image Synthesis with Latent Diffusion Models",
    "source_paper_url": "https://arxiv.org/pdf/2112.10752.pdf",
    "year": "2022",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "69",
    "excerpt": "This attack [CITATION] uses a task-ignoring text (e.g., “Ignore my previous instructions.”) to explicitly tell the LLM that the target task should be ignored. Specifically, given the target data $x^t$ , injected instruction $s^e$, and injected data $x^e$, this attack crafts \\tilde{x} by appending a task-ignoring text to $x^t$ before concatenating with ssse and $x^e$.",
    "target_paper_title": "Ignore Previous Prompt: Attack Techniques For Language Models",
    "target_paper_url": "https://arxiv.org/pdf/2211.09527.pdf",
    "source_paper_title": "Prompt Injection attack against LLM-integrated Applications",
    "source_paper_url": "https://arxiv.org/pdf/2306.05499.pdf",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "86",
    "excerpt": "To mitigate this relational understanding issue, a composition-aware hard negative mining strategy (NegCLIP) is introduced in [CITATION]. Note that this strategy is extremely lightweight, and can be seamlessly integrated as an additional fine-tuning stage in enhancing CLIP’s text understanding ability",
    "target_paper_title": "When and why vision-language models behave like bags-of-words, and what to do about it?",
    "target_paper_url": "https://arxiv.org/pdf/2210.01936.pdf",
    "source_paper_title": "An Inverse Scaling Law for CLIP Training",
    "source_paper_url": "https://arxiv.org/pdf/2305.07017.pdf",
    "year": "2023",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "88",
    "excerpt": "More specifically, these strategies employ Plackett-Luce (PL) ranking models [38, 48] to enhance the likelihood of achieving the most accurate item ordering. In RankCLIP, we incorporate ListMLE [CITATION] as part of our training objective to optimize both in-modal and cross-modal ranking consistencies.",
    "target_paper_title": "Learning to Rank: From Pairwise Approach to Listwise Approach",
    "target_paper_url": "http://icml2008.cs.helsinki.fi/papers/167.pdf",
    "source_paper_title": "RankCLIP: Ranking-Consistent Language-Image Pretraining",
    "source_paper_url": "https://arxiv.org/pdf/2404.09387.pdf",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "92",
    "excerpt": "Recent focus has been on synthetic methods like Deductive Databases (DD) [CITATION] that mimic human-like proving techniques and produce intelligible proofs by treating the problem of theorem proving as a step-by-step search problem using a set of geometry axioms.",
    "target_paper_title": "A Deductive Database Approach to Automated Geometry Theorem Proving and Discovering",
    "target_paper_url": "https://link.springer.com/article/10.1023/A:1006171315513",
    "source_paper_title": "Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry",
    "source_paper_url": "https://arxiv.org/pdf/2404.06405",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "104",
    "excerpt": "Sentiment analysis: we adopt the SST-2 [CITATION] dataset from the GLUE",
    "target_paper_title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "target_paper_url": "https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf",
    "source_paper_title": "PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts",
    "source_paper_url": "https://arxiv.org/pdf/2306.04528",
    "year": "2023",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "120",
    "excerpt": "[CITATION] advocates the development of a theory of clustering that will be “independent of any particular algorithm, objective function, or generative data model. They suggest three axioms, aimed to define what a clustering function is, each sounding plausible, and shows that these seemingly natural axioms lead to a contradiction - there exists no function that satisfies all three requirements.",
    "target_paper_title": "An Impossibility Theorem for Clustering",
    "target_paper_url": "https://dl.acm.org/doi/10.5555/2968618.2968676",
    "source_paper_title": "Measures of Clustering Quality: A Working Set of Axioms for Clustering",
    "source_paper_url": "https://proceedings.neurips.cc/paper_files/paper/2008/file/beed13602b9b0e6ecb5b568ff5058f07-Paper.pdf",
    "year": "2008",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "121",
    "excerpt": "[CITATION] show: No computable learner can non-uniformly learn the class $\\mathcal{H}_{comp}$, the class of all computable functions from $\\mathbb{N}$ to {0, 1}",
    "target_paper_title": "Statistical learning of arbitrary computable classifiers.",
    "target_paper_url": "https://arxiv.org/pdf/0806.3537",
    "source_paper_title": "On Learnability with Computable Learners",
    "source_paper_url": "https://proceedings.mlr.press/v117/agarwal20b/agarwal20b.pdf",
    "year": "2008",
    "split": "train",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "122",
    "excerpt": "Significant progress was made by [CITATION], who gave a characterization of proper strong computable PAC learning in terms of the computability of a Empirical Risk Minimizer (ERM) and who constructed a class of finite VC dimension which is not computable PAC learnable, even in the improper sense. ",
    "target_paper_title": "On characterizations of learnability with computable learners",
    "target_paper_url": "https://arxiv.org/pdf/2202.05041",
    "source_paper_title": "Find a witness or shatter: the landscape of computable PAC learning",
    "source_paper_url": "https://arxiv.org/pdf/2302.04731",
    "year": "2023",
    "split": "train",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "128",
    "excerpt": "Contrastive vision-language representation learning has recently emerged as an effective technique to learn representations with weak supervision that work for a wide range of tasks and have intriguing properties, such as strong zero-shot abilities. However, our understanding of the learned representation is in its infancy. For instance, recent work showed the presence of a modality gap and attributed it to the cone effect of model initialization and the contrastive loss [CITATION].",
    "target_paper_title": "Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning",
    "target_paper_url": "https://arxiv.org/pdf/2203.02053",
    "source_paper_title": "Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Representation Learning",
    "source_paper_url": "https://arxiv.org/pdf/2404.07983",
    "year": "2022",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "140",
    "excerpt": "We use the large-scale online continual learning dataset CLOC [CITATION], which contains 39 million time-stamped images exhibiting natural distribution shifts. The task is to identify the geolocation of a given image where the total number of geolocation labels is 712.",
    "target_paper_title": "Online Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data",
    "target_paper_url": "https://arxiv.org/pdf/2108.09020",
    "source_paper_title": "Real-Time Evaluation in Online Continual Learning: A New Hope",
    "source_paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ghunaim_Real-Time_Evaluation_in_Online_Continual_Learning_A_New_Hope_CVPR_2023_paper.pdf",
    "year": "2023",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "152",
    "excerpt": "To the best of our knowledge, there is only one method, QII, that provably provides differentially private black-box post-hoc model explanations [CITATION], protecting the explanation data. QII introduces Shapley value based model explanations, which have become a popular model explanation framework",
    "target_paper_title": "Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems",
    "target_paper_url": "https://ieeexplore.ieee.org/document/7546525",
    "source_paper_title": "Model Explanations with Differential Privacy",
    "source_paper_url": "https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533235",
    "year": "2022",
    "split": "train",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "164",
    "excerpt": "KD-DTI is dataset for drug-target-interaction introduced by [CITATION], consisting of 12k/1k/1.3k documents as the train/validation/test set. ",
    "target_paper_title": "Discovering drug-target interaction knowledge from biomedical literature",
    "target_paper_url": "https://arxiv.org/pdf/2109.13187",
    "source_paper_title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining",
    "source_paper_url": "https://arxiv.org/pdf/2210.10341",
    "year": "2023",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "177",
    "excerpt": "We define the robotics data mixture used across all of the experiments as the data from 9 manipulators, and taken from RT-1 [8], QT-Opt [66], Bridge [95], Task Agnostic Robot Play [126, 127], Jaco Play [128], Cable Routing [CITATION], RoboTurk [86], NYU VINN [130], Austin VIOLA [131], Berkeley Autolab UR5 [132], TOTO [133] and Language Table [91] datasets.",
    "target_paper_title": "Multi-Stage Cable Routing through Hierarchical Imitation Learning",
    "target_paper_url": "https://arxiv.org/pdf/2307.08927",
    "source_paper_title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models",
    "source_paper_url": "https://arxiv.org/pdf/2310.08864v4",
    "year": "2023",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "187",
    "excerpt": "For readability scores, we report the Simple Measure of Gobbledygook (SMOG) score [CITATION] and the Flesch Reading Ease (FRE) score [28]",
    "target_paper_title": "SMOG Grading-a New Readability Formula",
    "target_paper_url": "https://ogg.osu.edu/media/documents/health_lit/WRRSMOG_Readability_Formula_G._Harry_McLaughlin__1969_.pdf",
    "source_paper_title": "DOCCI: Descriptions of Connected and Contrasting Images",
    "source_paper_url": "https://arxiv.org/pdf/2404.19753",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "192",
    "excerpt": "For this task, we use the Comparative Question Completion dataset introduced by [CITATION]. This consists of questions in which one of a pair of coordinated elements is masked; the target is the masked phrase",
    "target_paper_title": "What’s the best place for an ai conference, vancouver or ___: Why completing comparative questions is difficult ",
    "target_paper_url": "https://arxiv.org/pdf/2104.01940",
    "source_paper_title": "Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding",
    "source_paper_url": "https://arxiv.org/pdf/2303.12513",
    "year": "2023",
    "split": "train",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "203",
    "excerpt": "[CITATION] trained a deep convolutional network-based system (PhysNet) to predict the stability of block towers from simulated images similar to those in Figure 4A but with much simpler configurations of two, three or four cubical blocks stacked vertically.",
    "target_paper_title": "Learning Physical Intuition of Block Towers by Example.",
    "target_paper_url": "https://arxiv.org/pdf/1603.01312",
    "source_paper_title": "Building Machines That Learn and Think Like People",
    "source_paper_url": "https://arxiv.org/pdf/1604.00289",
    "year": "2016",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "207",
    "excerpt": "[CITATION] propose two calibration measures to resolve this issue, which they call Adaptive Calibration Error (ACE) and Static Calibration Error (SCE). ACE and SCE extend ECE by measuring calibration over all classes in each bin, rather than just the predicted class.",
    "target_paper_title": "Measuring Calibration in Deep Learning",
    "target_paper_url": "https://openreview.net/forum?id=r1la7krKPS",
    "source_paper_title": "The Calibration Generalization Gap",
    "source_paper_url": "https://arxiv.org/pdf/2210.01964",
    "year": "2022",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "215",
    "excerpt": "Contrastive vision-language representation learning has recently emerged as an effective technique to learn representations with weak supervision that work for a wide range of tasks and have intriguing properties, such as strong zero-shot abilities. However, our understanding of the learned representation is in its infancy. For instance, recent work showed the presence of a modality gap and attributed it to the cone effect of model initialization and the contrastive loss [CITATION].",
    "target_paper_title": "Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning",
    "target_paper_url": "https://arxiv.org/pdf/2203.02053.pdf",
    "source_paper_title": "Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Representation Learning",
    "source_paper_url": "https://arxiv.org/pdf/2404.07983",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "232",
    "excerpt": "The affinity matrix of spectral clustering is a natural target for rank reduction. In particular, [CITATION] have used the Nystr¨om approximation, which samples columns of the affinity matrix and approximates the full matrix by using correlations between the sampled columns and the remaining columns.",
    "target_paper_title": "Spectral Grouping Using the Nystr ¨om Method",
    "target_paper_url": "https://math.ucdavis.edu/~saito/courses/ACHA.READ.S03/fbcm-pami-nystrom.pdf",
    "source_paper_title": "Fast Approximate Spectral Clustering",
    "source_paper_url": "https://digitalassets.lib.berkeley.edu/techreports/ucb/text/EECS-2009-45.pdf",
    "year": "2009",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "237",
    "excerpt": "RCA [CITATION] is intermediate between PCA and LDA in its use of labeled data. Specifically, RCA makes use of so-called “chunklet” information, or subclass membership assignments.",
    "target_paper_title": "Adjustment learning and relevant component analysis",
    "target_paper_url": "https://www.semanticscholar.org/paper/Adjustment-Learning-and-Relevant-Component-Analysis-Shental-Hertz/5f619c286efec9931ac0f52d62bc149c62cdbf6e",
    "source_paper_title": "Distance Metric Learning for Large Margin Nearest Neighbor Classification",
    "source_paper_url": "https://jmlr.csail.mit.edu/papers/volume10/weinberger09a/weinberger09a.pdf",
    "year": "2009",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "243",
    "excerpt": "In particular, on [CITATION], which consists of images of common objects crowd-sourced from six different regions across the world, we find that using translated multilingual captions makes CLIP perform better on all regions, with the biggest gain coming from Africa images (5.5%) and the second biggest gain coming from the Europe region.",
    "target_paper_title": "Geode: a geographically diverse evaluation dataset for object recognition",
    "target_paper_url": "https://arxiv.org/pdf/2301.02560",
    "source_paper_title": "Multilingual Diversity Improves Vision-Language Representations",
    "source_paper_url": "https://arxiv.org/pdf/2405.16915",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "256",
    "excerpt": "[CITATION] empirically determine that the effective context length of CLIP is less than 20 tokens and propose an algorithm to stretch the positional encoding, improving performance on longer texts",
    "target_paper_title": "Long-CLIP: Unlocking the Long-Text Capability of CLIP",
    "target_paper_url": "https://arxiv.org/pdf/2403.15378",
    "source_paper_title": "Jina CLIP: Your CLIP Model Is Also Your Text Retriever",
    "source_paper_url": "https://arxiv.org/pdf/2405.20204",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "258",
    "excerpt": "We build upon GIT [CITATION], an auto-regressive image-to-text generative model. ",
    "target_paper_title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "target_paper_url": "https://arxiv.org/pdf/2305.05065",
    "source_paper_title": "A Generative Approach for Wikipedia-Scale Visual Entity Recognition",
    "source_paper_url": "https://arxiv.org/pdf/2403.02041",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "273",
    "excerpt": "[CITATION] famously introduced a selective SSM block, that incorporates structured SSMs with hardware-aware state expansion, leading to a highly efficient recurrent architecture that is competitive to Transformer.",
    "target_paper_title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
    "target_paper_url": "https://arxiv.org/pdf/2312.00752",
    "source_paper_title": "Mamba-R: Vision Mamba ALSO Needs Registers",
    "source_paper_url": "https://arxiv.org/pdf/2405.14858",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "276",
    "excerpt": "Current research have also provided valuable insights into the grokking phenomenon from the dynamics of learning. [CITATION] reported that the grokking happens exclusively in accordance to a slingshot effect, which corresponding to a cyclic phase transitions between stable-and-unstable training regimes and the norm growth-and-plateau of the last layer weights",
    "target_paper_title": "The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon",
    "target_paper_url": "https://arxiv.org/pdf/2206.04817",
    "source_paper_title": "Deep Grokking: Would Deep Neural Networks Generalize Better?",
    "source_paper_url": "https://arxiv.org/pdf/2405.19454",
    "year": "2024",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  },
  {
    "id": "278",
    "excerpt": "More recently, researchers have created a more realistic code synthesis benchmark by collecting GitHub issues along with the corresponding code base together with tests to measure the ability of LLMs to perform real-world software engineering tasks [CITATION]. ",
    "target_paper_title": "Swe-bench: Can language models resolve real-world github issues?",
    "target_paper_url": "https://arxiv.org/pdf/2310.06770",
    "source_paper_title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation",
    "source_paper_url": "https://proceedings.neurips.cc/paper_files/paper/2023/file/43e9d647ccd3e4b7b5baab53f0368686-Paper-Conference.pdf",
    "year": "2023",
    "split": "test",
    "Attributable": true,
    "Unambiguous": true,
    "NonTrivial": true,
    "Reasonable": true,
    "PassesAll": true,
    "KeepAfterFiltering": true
  }
]